# LoggerFactory 日志

slf4j 日志记录器

Logger必须作为类的静态变量使用

创建日志记录器方法:(最好声明加final关键字)

```java
    //private static final Logger logger = LoggerFactory.getLogger(Slf4jTest.class);// slf4j日志记录器
    private static final Logger logger = LoggerFactory.getLogger(Slf4jTest.class.getName());// slf4j日志记录器
public static void main(String[] args) {

        // 普通的日志记录
        logger.debug("普通的日志记录");

        // {}占位符记录日志
        for (int i = 0; i < 3; i++) {
            logger.debug("这是第{}条记录", i);
        }

        // 用\转义{}
        logger.debug("Set \\{} differs from {}", "3"); // output:Set {} differs
                                                        // from 3

        // 两个参数
        logger.debug("两个占位符，可以传两个参数{}----{}", 1, 2);

        // 多个参数(可变参数)
        logger.debug("debug:多个占位符，{},{},{},{}", 1, 2, 3, 4);

        // 多个参数(可变参数)
        logger.info("info:多个占位符，{},{},{},{}", 1, 2, 3, 4);

        // 多个参数(可变参数)
        logger.error("error:多个占位符，{},{},{},{}", 1, 2, 3, 4);

    }
```

**结果:**

```
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[DEBUG] 普通的日志记录
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[DEBUG] 这是第0条记录
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[DEBUG] 这是第1条记录
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[DEBUG] 这是第2条记录
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[DEBUG] Set {} differs from 3
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[DEBUG] 两个占位符，可以传两个参数1----2
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[DEBUG] debug:多个占位符，1,2,3,4
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[INFO] info:多个占位符，1,2,3,4
2018-08-18 10:58:38 [cn.xm.exam.test.Slf4jTest]-[ERROR] error:多个占位符，1,2,3,4
```

```
每个Logger都被了一个日志级别（log level），用来控制日志信息的输出。日志级别从高到低分为：
A：off         最高等级，用于关闭所有日志记录。
B：fatal       指出每个严重的错误事件将会导致应用程序的退出。
C：error      指出虽然发生错误事件，但仍然不影响系统的继续运行。
D：warm     表明会出现潜在的错误情形。
E：info         一般和在粗粒度级别上，强调应用程序的运行全程。
F：debug     一般用于细粒度级别上，对调试应用程序非常有帮助。
G：all           最低等级，用于打开所有日志记录。

```

# amqpTemplate 消息队列

![](https://raw.githubusercontent.com/wuqifan1098/picBed/master/20190701202917.png)

Advanced Message Queue，高级消息队列协议。

# RabbitMQ

AMQP:Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。

RabbitMQ 是一个由Erlang语言开发的AMQP的开源实现。（PS:前几天有篇文章介绍了阿里P10的淘宝褚霸，就是erlang大神）。支持多种客户端。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。具体特点如下：

1、可靠性

RabbitMQ 使用一些机制来保证可靠性，如持久化，传输确认、发布确认。

2、灵活的路由

在消息进入队列之前，通过Exchange来路由消息。对于典型的路由功能，RabbitMQ 提供了内置的Exchange来实现。针对更复杂的路由功能。可以将多个Exchange 绑定在一起，也通过插件机制实现自己的 Exchange。

3、消息集群

多个RabbitMQ 服务器可以组成一个集群，形成一个逻辑Broker.

4、高可用

队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列任然可用。

5、多种协议

RabbitMQ支持多种消息队列协议。比如STOMP、MQTT等等

6、多语言客户端

RabbitMQ支持多种语言，比如java/Ruby等

7、管理界面

RabbitMQ提供了一个易用的用户界面。使得用户可有监控和管理Broker的许多方面

8、跟踪机制

如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出

9、插件机制

RabbitMQ提供了许多插件，从多方面进行扩展，也可以编写自己的插件

## 模型

![](https://raw.githubusercontent.com/wuqifan1098/picBed/master/20190701203345.png)

1、Message

消息，消息是不具名的，它由消息头和消息体组成，消息体是不透明的。而消息头则由一系列的可选属性组成。包括routing-key(路由键)、priority(相对于其他消息的优先权)、delivery-mode(指出该消息可能需要持久性存储)等

2、Publisher

消息的生产者，也是一个向交换器发布消息的客户端应用程序

3、Exchange

交换器，*用来接收生产者发送的消息并将这些消息路由给服务器中的队列。*

4、Binding

绑定，**用于消息队列和交换器之间的关联**。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则。所以可以将交换器理解成一个由绑定构成的路由表。

5、Queue

**消息队列，用来保存消息直到发送给消费者。**它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面。等待消息消费者连接到这个队列将其取走。

6、Connection

网络连接

7、Channel

信道，多路复用连接中的一条独立的双向数据流通道。

8、Consumer

消息的消费者，表示一个从消息队列中取得消息的客户端应用程序

9、Virtual Host

虚拟主机、表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个vhost 本质上就是一个mini版的RabbitMQ服务器。拥有自己的队列、交换器、绑定、和权限机制。vhost是AMQP概念的基础。必须在连接时指定，RabbitMQ默认的Vhost是

10、Broker

表示消息队列服务器实体。

## 工作模式

Exchange 有四种类型：Direct、Topic、Headers 和 Fanout 。

- Direct：该类型的行为是“先匹配，再投送”，即在绑定时设定一个 **routing_key**，消息的**routing_key** 匹配时，才会被交换器投送到绑定的队列中去。
- Topic：按规则转发消息（最灵活）。
- Headers：设置 header attribute 参数类型的交换机。
- Fanout：转发消息到所有绑定队列。

> headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了,这里不再详细介绍

![](https://raw.githubusercontent.com/wuqifan1098/picBed/master/Direct%20Mode.png)

Direct Exchange **是 RabbitMQ 默认的交换机模式，也是最简单的模式**，根据 key 全文匹配去寻找队列。

消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配.它是完全匹配、单播的模式。

![](https://raw.githubusercontent.com/wuqifan1098/picBed/master/Topic%20mode.png)

**Topic Exchange 转发消息主要是根据通配符。**在这种交换机下，队列和交换机的绑定会定义一种路由模式，那么，通配符就要在这种路由模式和路由键之间匹配后交换机才能转发消息。

在这种交换机模式下：

- 路由键必须是一串字符，用句号（.）隔开，如 agreements.us，或者 agreements.eu.stockholm 等。

topic 和 direct 类似，只是匹配上支持了“模式”，在“点分”的 `routing_key` 形式中，可以使用两个通配符：

- `*`表示一个词。
- `#`表示零个或多个词。

![](https://raw.githubusercontent.com/wuqifan1098/picBed/master/Fanout%20mode.png)

Fanout Exchange 消息广播的模式，不管路由键或者是路由模式，**会把消息发给绑定给它的全部队列**，如果配置了`routing_key`会被忽略。

参考 ：https://yq.aliyun.com/articles/640636

# InitializingBean

## 概述

从接口的名字上不难发现，InitializingBean 的作用就是在 bean 初始化后执行定制化的操作。

Spring 容器中的 Bean 是有生命周期的，Spring 允许在 Bean 在初始化完成后以及 Bean 销毁前执行特定的操作，常用的设定方式有以下三种：

- 通过实现 InitializingBean/DisposableBean 接口来定制初始化之后/销毁之前的操作方法；
- 通过 <bean> 元素的 init-method/destroy-method 属性指定初始化之后 /销毁之前调用的操作方法；
- 在指定方法上加上@PostConstruct 或@PreDestroy注解来制定该方法是在初始化之后还是销毁之前调用。

## InitializingBean vs init-method

接口定义如下：

```java
public interface InitializingBean {
    void afterPropertiesSet() throws Exception;
}
```

接口只有一个方法`afterPropertiesSet`，此方法的调用入口是负责加载 spring bean 的`AbstractAutowireCapableBeanFactory`，源码如下：

```java
    protected void invokeInitMethods(String beanName, final Object bean, @Nullable RootBeanDefinition mbd)
            throws Throwable {

        boolean isInitializingBean = (bean instanceof InitializingBean);
        if (isInitializingBean && (mbd == null || !mbd.isExternallyManagedInitMethod("afterPropertiesSet"))) {
            if (logger.isDebugEnabled()) {
                logger.debug("Invoking afterPropertiesSet() on bean with name '" + beanName + "'");
            }
            if (System.getSecurityManager() != null) {
                try {
                    AccessController.doPrivileged((PrivilegedExceptionAction<Object>) () -> {
                        ((InitializingBean) bean).afterPropertiesSet();
                        return null;
                    }, getAccessControlContext());
                }
                catch (PrivilegedActionException pae) {
                    throw pae.getException();
                }
            }
            else {
                ((InitializingBean) bean).afterPropertiesSet();
            }
        }
```

从这段源码可以得出以下结论：

1. spring为bean提供了两种初始化bean的方式，**实现InitializingBean接口，实现afterPropertiesSet方法**，或者在配置文件中通过init-method指定，两种方式可以同时使用
2. 实现InitializingBean接口是**直接调用afterPropertiesSet方法，比通过反射调用init-method指定的方法效率相对来说要高点。**但是init-method方式消除了对spring的依赖
3. 先调用afterPropertiesSet，再执行 init-method 方法，如果调用afterPropertiesSet方法时出错，则不调用init-method指定的方法。

## @PostConstruct

通过 debug 和调用栈找到类`InitDestroyAnnotationBeanPostProcessor`, 其中的核心方法，即 `@PostConstruct` 方法调用的入口：

```java
    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
        LifecycleMetadata metadata = findLifecycleMetadata(bean.getClass());
        try {
            metadata.invokeInitMethods(bean, beanName);
        }
        catch (InvocationTargetException ex) {
            throw new BeanCreationException(beanName, "Invocation of init method failed", ex.getTargetException());
        }
        catch (Throwable ex) {
            throw new BeanCreationException(beanName, "Failed to invoke init method", ex);
        }
        return bean;
    }
```

从命名上，我们就可以得到某些信息——这是一个BeanPostProcessor。想到了什么？在[也谈Spring容器的生命周期](http://sexycoding.iteye.com/blog/1046775)中，提到过BeanPostProcessor的postProcessBeforeInitialization是在Bean生命周期中afterPropertiesSet和init-method之前被调用的。另外通过跟踪，`@PostConstruct`方法的调用方式也是通过发射机制。

# 总结

1. spring bean的初始化执行顺序：构造方法 --> `@PostConstruct`注解的方法 --> `afterPropertiesSet`方法 --> `init-method`指定的方法。具体可以参考例子
2. `afterPropertiesSet`通过接口实现方式调用（效率上高一点），`@PostConstruct`和`init-method`都是通过反射机制调用

# Nginx 水平扩展

## [nginx和tomcat的区别](https://www.cnblogs.com/flypie/p/5153702.html)

web上的server都叫web server，但是大家分工也有不同的。

nginx常用做静态内容服务和代理服务器（不是你FQ那个代理），直面外来请求转发给后面的应用服务（tomcat，django什么的），tomcat更多用来做做一个应用容器，让java web app跑在里面的东西，对应同级别的有jboss,jetty等东西。

但是事无绝对，nginx也可以通过模块开发来提供应用功能，tomcat也可以直接提供http服务，通常用在内网和不需要流控等小型服务的场景。

apache用的越来越少了，大体上和nginx功能重合的更多。

 严格的来说，Apache/Nginx 应该叫做「HTTP Server」；而 Tomcat 则是一个「Application Server」，或者更准确的来说，是一个「Servlet/JSP」应用的容器（Ruby/Python 等其他语言开发的应用也无法直接运行在 Tomcat 上）。

# Nginx的用武之地

Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；Nginx可以作为一个HTTP服务器进行网站的发布处理，另外Nginx可以作为反向代理进行负载均衡的实现。

## 关于代理

说到代理，首先我们要明确一个概念，所谓代理就是一个代表、一个渠道；

此时就涉及到两个角色，一个是被代理角色，一个是目标角色，被代理角色通过这个代理访问目标角色完成一些任务的过程称为代理操作过程；如同生活中的专卖店~客人到adidas专卖店买了一双鞋，这个专卖店就是代理，被代理角色就是adidas厂家，目标角色就是用户。

## 正向代理

说反向代理之前，我们先看看正向代理，正向代理也是大家最常接触的到的代理模式，我们会从两个方面来说关于正向代理的处理模式，分别从软件方面和生活方面来解释一下什么叫正向代理。

在如今的网络环境下，我们如果由于技术需要要去访问国外的某些网站，此时你会发现位于国外的某网站我们通过浏览器是没有办法访问的，此时大家可能都会用一个操作FQ进行访问，FQ的方式主要是找到一个可以访问国外网站的代理服务器，我们将请求发送给代理服务器，代理服务器去访问国外的网站，然后将访问到的数据传递给我们！

上述这样的代理模式称为正向代理，正向代理最大的特点是客户端非常明确要访问的服务器地址；服务器只清楚请求来自哪个代理服务器，而不清楚来自哪个具体的客户端；正向代理模式屏蔽或者隐藏了真实客户端信息。来看个示意图（我把客户端和正向代理框在一块，同属于一个环境，后面我有介绍）：

![img](https://img2018.cnblogs.com/blog/1202586/201812/1202586-20181211123717325-1261206014.png)

客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的IP地址，还有代理程序的端口。如图。

![img](https://img2018.cnblogs.com/blog/1202586/201812/1202586-20181211121039404-1910765480.png)

总结来说：正向代理，"它代理的是客户端，代客户端发出请求"，是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。

正向代理的用途：
（1）访问原来无法访问的资源，如Google
（2） 可以做缓存，加速访问资源
（3）对客户端访问授权，上网进行认证
（4）代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息

## 反向代理

明白了什么是正向代理，我们继续看关于反向代理的处理方式，举例如我大天朝的某宝网站，每天同时连接到网站的访问人数已经爆表，单个服务器远远不能满足人民日益增长的购买欲望了，此时就出现了一个大家耳熟能详的名词：分布式部署；也就是通过部署多台服务器来解决访问人数限制的问题；某宝网站中大部分功能也是直接使用Nginx进行反向代理实现的，并且通过封装Nginx和其他的组件之后起了个高大上的名字：Tengine，有兴趣的童鞋可以访问Tengine的官网查看具体的信息：http://tengine.taobao.org/。那么反向代理具体是通过什么样的方式实现的分布式的集群操作呢，我们先看一个示意图（我把服务器和反向代理框在一块，同属于一个环境，后面我有介绍）：

![img](https://images2018.cnblogs.com/blog/1202586/201804/1202586-20180406175939873-925019958.png)

通过上述的图解大家就可以看清楚了，多个客户端给服务器发送的请求，Nginx服务器接收到之后，按照一定的规则分发给了后端的业务处理服务器进行处理了。此时~请求的来源也就是客户端是明确的，但是请求具体由哪台服务器处理的并不明确了，Nginx扮演的就是一个反向代理角色。

客户端是无感知代理的存在的，反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。因为客户端不需要任何配置就可以访问。

反向代理，"它代理的是服务端，代服务端接收请求"，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。

反向代理的作用：
（1）保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网
（2）负载均衡，通过反向代理服务器来优化网站的负载

### 项目场景

通常情况下，我们在实际项目操作时，正向代理和反向代理很有可能会存在在一个应用场景中，正向代理代理客户端的请求去访问目标服务器，目标服务器是一个反向单利服务器，反向代理了多台真实的业务处理服务器。具体的拓扑图如下：

![img](https://images2018.cnblogs.com/blog/1202586/201804/1202586-20180406180130452-1246060303.png)

## 二者区别

截了一张图来说明正向代理和反向代理二者之间的区别，如图。

![img](https://img2018.cnblogs.com/blog/1202586/201812/1202586-20181211122806997-940664368.png)

图解：

在正向代理中，Proxy和Client同属于一个LAN（图中方框内），隐藏了客户端信息；

在反向代理中，Proxy和Server同属于一个LAN（图中方框内），隐藏了服务端信息；

实际上，Proxy在两种代理中做的事情都是替服务器代为收发请求和响应，不过从结构上看正好左右互换了一下，所以把后出现的那种代理方式称为反向代理了。

## 负载均衡

我们已经明确了所谓代理服务器的概念，那么接下来，Nginx扮演了反向代理服务器的角色，它是以依据什么样的规则进行请求分发的呢？不用的项目应用场景，分发的规则是否可以控制呢？

这里提到的客户端发送的、Nginx反向代理服务器接收到的请求数量，就是我们说的负载量。

请求数量按照一定的规则进行分发到不同的服务器处理的规则，就是一种均衡规则。

所以~将服务器接收到的请求按照规则分发的过程，称为负载均衡。

负载均衡在实际项目操作过程中，有硬件负载均衡和软件负载均衡两种，硬件负载均衡也称为硬负载，如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性等等有非常好的保障，如中国移动中国联通这样的公司才会选择硬负载进行操作；更多的公司考虑到成本原因，会选择使用软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。

![img](https://images2018.cnblogs.com/blog/1202586/201804/1202586-20180406180405961-333776342.png)

Nginx支持的负载均衡调度算法方式如下：

1. weight轮询(默认，常用)：接收到的请求按照权重分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，Nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。 这种方式下，可以给不同的后端服务器设置一个权重值(weight)，用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。
2. ip_hash（常用）：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。
3. fair：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是Nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块。
4. url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。

#  几种常用web服务器对比

| **对比项\服务器** | **Apache** | **Nginx** | **Lighttpd** |
| ----------------- | ---------- | --------- | ------------ |
| Proxy代理         | 非常好     | 非常好    | 一般         |
| Rewriter          | 好         | 非常好    | 一般         |
| Fcgi              | 不好       | 好        | 非常好       |
| 热部署            | 不支持     | 支持      | 不支持       |
| 系统压力          | 很大       | 很小      | 比较小       |
| 稳定性            | 好         | 非常好    | 不好         |
| 安全性            | 好         | 一般      | 一般         |
| 静态文件处理      | 一般       | 非常好    | 好           |
| 反向代理          | 一般       | 非常好    | 一般         |

参考 : https://www.cnblogs.com/wcwnina/p/8728391.html

# 水平扩展

**垂直扩展（Scale Up）**与**水平扩展（Scale Out）**。

`垂直扩展`：提升单机处理能力。垂直扩展的方式又有两种：

1. 增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；
2. 提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间。

在互联网业务发展非常迅猛的早期，如果预算不是问题，强烈建议使用“增强单机硬件性能”的方式提升系统并发能力，因为这个阶段，公司的战略往往是发展业务抢时间，而“增强单机硬件性能”往往是最快的方法。

不管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：**单机性能总是有极限的**。所以**互联网分布式架构设计高并发终极解决方案还是水平扩展**。

`水平扩展`：只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践，是本文重点讨论的内容。

### 三、常见的互联网分层架构

![img](https://images2015.cnblogs.com/blog/1151134/201706/1151134-20170601181003133-657426538.png)

常见互联网分布式架构如上，分为：

1. 客户端层：典型调用方是浏览器browser或者手机应用APP
2. 反向代理层：系统入口，反向代理
3. 站点应用层：实现核心应用逻辑，返回html或者json
4. 服务层：如果实现了服务化，就有这一层
5. 数据-缓存层：缓存加速访问存储
6. 数据-数据库层：数据库固化数据存储

整个系统各层次的水平扩展，又分别是如何实施的呢？

### 四、分层水平扩展架构实践

**反向代理层的水平扩展**

![img](https://images2015.cnblogs.com/blog/1151134/201706/1151134-20170601181220727-1373004690.png)

反向代理层的水平扩展，是通过“DNS轮询”实现的：dns-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问dns-server，会轮询返回这些ip。

当nginx成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip，就能扩展反向代理层的性能，做到理论上的无限高并发。

**站点层的水平扩展**

![img](https://images2015.cnblogs.com/blog/1151134/201706/1151134-20170601181423883-757482818.png)

 

站点层的水平扩展，是通过“nginx”实现的。通过修改nginx.conf，可以设置多个web后端。

当web后端成为瓶颈的时候，只要增加服务器数量，新增web服务的部署，在nginx配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。

**服务层的水平扩展**

![img](https://images2015.cnblogs.com/blog/1151134/201706/1151134-20170601181540727-1420144971.png)

站点层通过RPC-client调用下游的服务层RPC-server时，RPC-client中的连接池会建立与下游服务多个连接，当服务成为瓶颈的时候，只要增加服务器数量，新增服务部署，在RPC-client处建立新的下游服务连接，就能扩展服务层性能，做到理论上的无限高并发。如果需要优雅的进行服务层自动扩容，这里可能需要配置中心里服务自动发现功能的支持。

**数据层的水平扩展**

在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库）水平拆分到不同服务器上去，以达到扩充系统性能的目的。

互联网数据层常见的水平拆分方式有这么几种，以数据库为例：

**按照范围水平拆分**

![img](https://images2015.cnblogs.com/blog/1151134/201706/1151134-20170601181656196-718003791.png)

每一个数据服务，存储一定范围的数据，上图为例：

- user0库，存储uid范围1-1kw
- user1库，存储uid范围1kw-2kw

这个方案的好处是：

- 规则简单，service只需判断一下uid范围就能路由到对应的存储服务；
- 数据均衡性较好；
- 比较容易扩展，可以随时加一个uid[2kw,3kw]的数据服务。

不足是：

- 请求的负载不一定均衡，一般来说，新注册的用户会比老用户更活跃，大range的服务请求压力会更大。

**按照哈希水平拆分**

![img](https://images2015.cnblogs.com/blog/1151134/201706/1151134-20170601181748821-5092464.png)

每一个数据库，存储某个key值hash后的部分数据，上图为例：

- user0库，存储偶数uid数据
- user1库，存储奇数uid数据

这个方案的好处是：

- 规则简单，service只需对uid进行hash能路由到对应的存储服务；
- 数据均衡性较好；
- 请求均匀性较好。

不足是：

- 不容易扩展，扩展一个数据服务，hash方法改变时候，可能需要进行数据迁移。

这里需要注意的是，通过水平拆分来扩充系统性能，与主从同步读写分离来扩充数据库性能的方式有本质的不同。

通过水平拆分扩展数据库性能：

1. 每个服务器上存储的数据量是总量的1/n，所以单机的性能也会有提升；
2. n个服务器上的数据没有交集，那个服务器上数据的并集是数据的全集；
3. 数据水平拆分到了n个服务器上，理论上读性能扩充了n倍，写性能也扩充了n倍（其实远不止n倍，因为单机的数据量变为了原来的1/n）。

通过主从同步读写分离扩展数据库性能：

1. 每个服务器上存储的数据量是和总量相同；
2. n个服务器上的数据都一样，都是全集；
3. 理论上读性能扩充了n倍，写仍然是单点，写性能不变。

缓存层的水平拆分和数据库层的水平拆分类似，也是以范围拆分和哈希拆分的方式居多，就不再展开。

### 五、总结

高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，**通过设计保证系统能够同时并行处理很多请求**。

**提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）**。前者垂直扩展可以通过提升单机硬件性能，或者提升单机架构性能，来提高并发性，但单机性能总是有极限的，**互联网分布式架构设计高并发终极解决方案还是后者：水平扩展**。

互联网分层架构中，各层次水平扩展的实践又有所不同：

1. 反向代理层可以通过“DNS轮询”的方式来进行水平扩展；
2. 站点层可以通过nginx来进行水平扩展；
3. 服务层可以通过服务连接池来进行水平扩展；
4. 数据库可以按照数据范围，或者数据哈希的方式来进行水平扩展。

各层实施水平扩展后，能够通过增加服务器数量的方式来提升系统的性能，做到理论上的性能无限。

参考：https://www.cnblogs.com/afee666/p/6930181.html