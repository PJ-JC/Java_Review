## **预备知识点**

**Bitmap和布隆过滤器(Bloom Filter)**

[https://blog.csdn.net/zdxiq000/article/details/57626464](https://link.zhihu.com/?target=https%3A//blog.csdn.net/zdxiq000/article/details/57626464)

## **Bitmap**

我们只想知道某个元素出现过没有。**如果为每个所有可能的值分配1个bit**，32bit的int所有可能取值需要内存空间为：

2^32bit=2^29Byte=512MB

但对于海量的、取值分布很均匀的集合进行去重，Bitmap极大地压缩了所需要的内存空间。**于此同时，还额外地完成了对原始数组的排序工作**。缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。

## **Bloom Filter**

如果说Bitmap对于每一个可能的整型值，通过直接寻址的方式进行映射，相当于使用了一个哈希函数，那布隆过滤器就是引入了k(k>1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。下图中是k=3时的布隆过滤器。

![img](https://pic3.zhimg.com/80/v2-38d92745c0665233c225ae39c35a1e7e_hd.jpg)

那么布隆过滤器的误差有多少？我们假设所有哈希函数散列足够均匀，散列后落到Bitmap每个位置的概率均等。

![img](https://pic1.zhimg.com/80/v2-7bccbb56a1ce6c3cfa9770b7f7974984_hd.jpg)

若以m=16nm=16n计算，Bitmap集合的大小为238bit=235Byte=32GB238bit=235Byte=32GB，此时的ε≈0.0005。并且要知道，以上计算的都是误差的上限。

布隆过滤器通过引入一定错误率，使得海量数据判重在可以接受的内存代价中得以实现。从上面的公式可以看出，随着集合中的元素不断输入过滤器中(nn增大)，误差将越来越大。但是，当Bitmap的大小mm（指bit数）足够大时，比如比所有可能出现的不重复元素个数还要大10倍以上时，错误概率是可以接受的。

这里有一个google实现的布隆过滤器，我们来看看它的误判率：

在这个实现中，Bitmap的集合m、输入的原始数集合n、哈希函数k的取值都是按照上面最优的方案选取的，默认情况下保证误判率ε=0.5k<0.03≈0.55，因而此时k=5。

而还有一个很有趣的地方是，实际使用的却并不是5个哈希函数。实际进行映射时，而是分别使用了一个64bit哈希函数的高、低32bit进行循环移位。注释中包含着这个算法的论文“Less Hashing, Same Performance: Building a Better Bloom Filter”，论文中指明其对过滤器性能没有明显影响。很明显这个实现对于m>232时的支持并不好，因为当大于231−1的下标在算法中并不能被映射到。